{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+Cx7tf1Gr4CJ0ZeQ277st",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DolBaKi/DolBaKi/blob/main/Studying/Slot_Machine_RL_0310.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 슬롯머신에서 돈 잘따는 강화학습 만들기\n",
        "왜? 아니 돈 꼻으면 속상하다고요\n",
        "\n",
        "돈을 얻으면 기부니가 좋아진다구연\n",
        "\n",
        "보상을 잘딸 수 있는 기계로 reward를 설정해준다\n",
        "\n",
        "지금까지 딴 평균값의 최대로 설정해서 돈 많이따자\n",
        "\n",
        "**my money don't jiggle jiggle**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7Rw-OW35SNVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 라이브러리를 import 해주도록 하겠습니다\n",
        "\n"
      ],
      "metadata": {
        "id": "4eky5UZ5T8OU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium[classic-control] # 라이브러리 인스톨"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3j3iQqLUdPM",
        "outputId": "03bd0035-63f6-4c91-a050-6ee570635582"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium[classic-control] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic-control]) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic-control]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic-control]) (4.10.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic-control]) (0.0.4)\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium[classic-control]) (2.5.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # 배열 관리 시스템 and something 관련 라이브러리\n",
        "import gymnasium as gym # 강화학습을 위한 기본 라이브러리\n",
        "import random # 랜덤 라이브러리"
      ],
      "metadata": {
        "id": "k5OFpdtFTvaE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 현재 슬롯머신 환경을 구현해주도록 하겠습니다."
      ],
      "metadata": {
        "id": "0IpfWqdwVzzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BanditEnv:\n",
        "    def __init__(self,num_bandits): # num_bandits:슬롯머신 수를 받습니다\n",
        "        self.num_bandits=num_bandits # 슬롯머신 수\n",
        "        self.action_space=list(range(num_bandits)) # 행동 가능한 모든 슬롯머신\n",
        "        self.observation_space=[0] # 상태는 의미가 없습니다. 틀에다가 가져다 붙혀넣는다고 생각하심 편해요\n",
        "    def reset(self):\n",
        "        self.mean=np.random.normal(size=self.num_bandits)*10\n",
        "        return 0 # 상태 리턴\n",
        "    def step(self,action):\n",
        "        state=0 # 상태는 없습니다. 결국엔 돌리던 말던 내(agent)가 변하는 것은 없습니다\n",
        "        reward=self.mean[action] # 선택에 따른 보상\n",
        "        done=False # 디버깅 용도로 사용한다고 합니다\n",
        "        return state,reward,done,{}"
      ],
      "metadata": {
        "id": "_8ovuwynUZ-9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 슬롯머신에서 가장 많은 돈을 따는 정책(Policy)를 구현해주도록 하겠습니다."
      ],
      "metadata": {
        "id": "hEqKfq5ZV6sw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Policy:\n",
        "    def __init__(self,num_bandits):\n",
        "        self.num_bandits=num_bandits # bandit 갯수 저장\n",
        "        initial_q=100 # 하나만 골라지는 문제를 해결하기 위한 값 초기화\n",
        "        self.q=[initial_q for _ in range(num_bandits)] # 평균값\n",
        "        self.n=[1 for _ in range(num_bandits)] # 뽑힌 갯수\n",
        "    def __call__(self,state):\n",
        "        p=random.randint(1,50)\n",
        "        if p==1:\n",
        "            action=random.randint(0,env.num_bandits) # 2%의 확률로 무작위로 돌리는 ε- greedy 알고리즘입니다\n",
        "        else:\n",
        "            action=np.argmax(self.q)  # q 내부에 있는 값들 중 가장 큰 값의 index\n",
        "        return action"
      ],
      "metadata": {
        "id": "FldZJ169Vca8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env=BanditEnv(10) # 슬롯머신 환경 설정\n",
        "state=env.reset() # 상태\n",
        "agent=Policy(10) # 나(agent)\n",
        "\n",
        "\n",
        "total_reward=0 # 보상의 합\n",
        "for t in range(100):\n",
        "    action=agent(state) # 98%의 확률로 평균 보상이 가장 큰 슬롯머신을 돌립니다\n",
        "    state,reward,done,_=env.step(action) # 상태,보상,끝,(debugging전용) 은 action의 슬롯머신을 돌렸을 때 리턴되어서 나오는 값들을 저장\n",
        "     # 평균을 구하는 코드\n",
        "    agent.n[action]+=1\n",
        "    agent.q[action]+=(reward-agent.q[action])/agent.n[action]\n",
        "     # 토탈 reward 저장\n",
        "    total_reward+=reward\n",
        "     # 출력\n",
        "    print(f\"action: {action}\")\n",
        "    print(f\"reward: {reward}\")\n",
        "\n",
        "print(f\"total: {total_reward}\")\n",
        "print(agent.n)"
      ],
      "metadata": {
        "id": "WML1cwU5W6rU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a779246-5dbb-4a63-b4c0-682ddc701bcb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action: 0\n",
            "reward: 7.230414132793049\n",
            "action: 1\n",
            "reward: 4.016761473346168\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 3\n",
            "reward: -4.537945320744444\n",
            "action: 4\n",
            "reward: -11.074740916933115\n",
            "action: 5\n",
            "reward: -7.288488465297899\n",
            "action: 6\n",
            "reward: 0.5912525042379325\n",
            "action: 7\n",
            "reward: 9.658379499342395\n",
            "action: 8\n",
            "reward: 9.627682205161548\n",
            "action: 9\n",
            "reward: -0.7375431925594921\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 7\n",
            "reward: 9.658379499342395\n",
            "action: 8\n",
            "reward: 9.627682205161548\n",
            "action: 0\n",
            "reward: 7.230414132793049\n",
            "action: 1\n",
            "reward: 4.016761473346168\n",
            "action: 6\n",
            "reward: 0.5912525042379325\n",
            "action: 9\n",
            "reward: -0.7375431925594921\n",
            "action: 3\n",
            "reward: -4.537945320744444\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 5\n",
            "reward: -7.288488465297899\n",
            "action: 4\n",
            "reward: -11.074740916933115\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 7\n",
            "reward: 9.658379499342395\n",
            "action: 8\n",
            "reward: 9.627682205161548\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 0\n",
            "reward: 7.230414132793049\n",
            "action: 1\n",
            "reward: 4.016761473346168\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 6\n",
            "reward: 0.5912525042379325\n",
            "action: 9\n",
            "reward: -0.7375431925594921\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 7\n",
            "reward: 9.658379499342395\n",
            "action: 8\n",
            "reward: 9.627682205161548\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 0\n",
            "reward: 7.230414132793049\n",
            "action: 3\n",
            "reward: -4.537945320744444\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 5\n",
            "reward: -7.288488465297899\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 1\n",
            "reward: 4.016761473346168\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 7\n",
            "reward: 9.658379499342395\n",
            "action: 8\n",
            "reward: 9.627682205161548\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 5\n",
            "reward: -7.288488465297899\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 4\n",
            "reward: -11.074740916933115\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 6\n",
            "reward: 0.5912525042379325\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 0\n",
            "reward: 7.230414132793049\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 7\n",
            "reward: 9.658379499342395\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 8\n",
            "reward: 9.627682205161548\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 9\n",
            "reward: -0.7375431925594921\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "action: 2\n",
            "reward: 23.094739872234346\n",
            "total: 1500.1374436631584\n",
            "[6, 5, 62, 4, 4, 5, 5, 7, 7, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L2U0XSAG0V8T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}